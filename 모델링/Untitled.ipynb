{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오리지널 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0, 10,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 10]], dtype=int8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "R = pd.read_pickle('MF_pivot.pickle')\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.0011\n",
      "User Latent P:\n",
      "[[ 0.38539342 -0.80334032 -0.71958647]\n",
      " [ 0.45580988  0.27206895  0.32237192]\n",
      " [ 0.69433071  0.21994371  0.35221235]\n",
      " ...\n",
      " [-0.54363269  0.36451851  0.2415186 ]\n",
      " [-0.7013237   0.31111689  1.2212096 ]\n",
      " [-0.29791432 -0.81801439  0.03388137]]\n",
      "Item Latent Q:\n",
      "[[ 0.24806098  0.46144143 -1.00380227 ... -1.48301955  0.54063701\n",
      "  -0.67415008]\n",
      " [ 0.15201278 -0.24498057  0.89021203 ... -0.16997052  0.28895068\n",
      "   0.26252262]\n",
      " [ 0.46756348  0.13587867 -0.06502794 ...  0.54377141  0.37175164\n",
      "   0.25386088]]\n",
      "P x Q:\n",
      "[[-0.36296928  0.27686281 -1.05520879 ... -0.82629235 -0.29127524\n",
      "  -0.65338287]\n",
      " [ 0.30515594  0.18748142 -0.23630712 ... -0.54692203  0.44488449\n",
      "  -0.1540224 ]\n",
      " [ 0.37035225  0.31436916 -0.52407785 ... -0.87556695  0.56986928\n",
      "  -0.32092997]\n",
      " ...\n",
      " [ 0.03348269 -0.30733737  0.85449304 ...  0.87559141 -0.09879514\n",
      "   0.5234965 ]\n",
      " [ 0.44431571 -0.23390106  0.90153757 ...  1.65125492  0.16472256\n",
      "   0.86449   ]\n",
      " [-0.18240787  0.06753138 -0.43136242 ...  0.59927481 -0.38483387\n",
      "  -0.00530716]]\n",
      "bias:\n",
      "7.696984752165587\n",
      "User Latent bias:\n",
      "[-0.63408687  0.18862709 -0.15982072 ...  0.22013032  0.28385074\n",
      "  0.09269955]\n",
      "Item Latent bias:\n",
      "[ 1.38319055 -3.09814619  0.21840098 ... -0.50070548 -0.209235\n",
      " -2.89493902]\n",
      "Final R matrix:\n",
      "[[8.08311915 4.2416145  6.22609007 ... 5.73590006 6.56238764 3.514576  ]\n",
      " [9.57395833 4.97494707 7.86770569 ... 6.83798433 8.12126133 4.83665043]\n",
      " [9.29070682 4.753387   7.23148716 ... 6.1608916  7.89779831 4.32129504]\n",
      " ...\n",
      " [9.33378832 4.51163152 8.99000909 ... 8.29200101 7.60908493 5.54567256]\n",
      " [9.80834176 4.64878825 9.10077405 ... 9.13138494 7.93632306 5.95038648]\n",
      " [8.99046698 4.7590695  7.57672287 ... 7.88825364 7.19561544 4.88943813]]\n",
      "Final RMSE:\n",
      "0.0010669215359588526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            for i in range(self._num_users):\n",
    "                for j in range(self._num_items):\n",
    "                    if self._R[i, j] > 0:\n",
    "                        self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(cost) / len(xi)\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)\n",
    "\n",
    "\n",
    "    def print_results(self):\n",
    "        \"\"\"\n",
    "        print fit results\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"User Latent P:\")\n",
    "        print(self._P)\n",
    "        print(\"Item Latent Q:\")\n",
    "        print(self._Q.T)\n",
    "        print(\"P x Q:\")\n",
    "        print(self._P.dot(self._Q.T))\n",
    "        print(\"bias:\")\n",
    "        print(self._b)\n",
    "        print(\"User Latent bias:\")\n",
    "        print(self._b_P)\n",
    "        print(\"Item Latent bias:\")\n",
    "        print(self._b_Q)\n",
    "        print(\"Final R matrix:\")\n",
    "        print(self.get_complete_matrix())\n",
    "        print(\"Final RMSE:\")\n",
    "        print(self._training_process[self._epochs-1][1])\n",
    "\n",
    "\n",
    "# run example\n",
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : (7 X 5)\n",
    "\n",
    "    \n",
    "    # P, Q is (7 X k), (k X 5) matrix\n",
    "    factorizer = MatrixFactorization(R, k=3, learning_rate=0.01, reg_param=0.01, epochs=10, verbose=True)\n",
    "    factorizer.fit()\n",
    "    factorizer.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.08311915, 4.2416145 , 6.22609007, ..., 5.73590006, 6.56238764,\n",
       "        3.514576  ],\n",
       "       [9.57395833, 4.97494707, 7.86770569, ..., 6.83798433, 8.12126133,\n",
       "        4.83665043],\n",
       "       [9.29070682, 4.753387  , 7.23148716, ..., 6.1608916 , 7.89779831,\n",
       "        4.32129504],\n",
       "       ...,\n",
       "       [9.33378832, 4.51163152, 8.99000909, ..., 8.29200101, 7.60908493,\n",
       "        5.54567256],\n",
       "       [9.80834176, 4.64878825, 9.10077405, ..., 9.13138494, 7.93632306,\n",
       "        5.95038648],\n",
       "       [8.99046698, 4.7590695 , 7.57672287, ..., 7.88825364, 7.19561544,\n",
       "        4.88943813]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF_model_matrix = factorizer.get_complete_matrix()\n",
    "MF_model_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82740"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MF_model_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7212"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MF_model_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(MF_model_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('MF_model_matrix.pickle', 'wb') as f:\n",
    "    pickle.dump(MF_model_matrix, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 설정\n",
    "- r_lambda: normalization parameter\n",
    "- alpha: confidence level\n",
    "- nf: dimension of latent vector of each user and item\n",
    "- initilzed values(40, 200, 40) are the best parameters from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_lambda = 40\n",
    "nf = 200\n",
    "alpha = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Factor Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = R.shape[0]  # nu: num of users\n",
    "ni = R.shape[1]  # ni: num of item\n",
    "print(nu)\n",
    "print(ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# initialize X and Y with very small values\n",
    "X = np.random.rand(nu, nf) * 0.01\n",
    "Y = np.random.rand(ni, nf) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Rating Matrix P\n",
    "- Convert original rating matrix R into P\n",
    "- Pui = 1 if Rui > 0\n",
    "- Pui = 0 if Rui = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.copy(R)\n",
    "P[P > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Matrix C\n",
    "- Cui = 1 + alpha * Rui\n",
    "- Cui means confidence level of certain rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1 + alpha * R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로스함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(C, P, xTy, X, Y, r_lambda):\n",
    "    predict_error = np.square(P - xTy)\n",
    "    confidence_error = np.sum(C * predict_error)\n",
    "    regularization = r_lambda * (np.sum(np.square(X)) + np.sum(np.square(Y)))\n",
    "    total_loss = confidence_error + regularization\n",
    "    return np.sum(predict_error), confidence_error, regularization, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_user(X, Y, C, P, nu, nf, r_lambda):\n",
    "    yT = np.transpose(Y)\n",
    "    for u in range(nu):\n",
    "        Cu = np.diag(C[u])\n",
    "        yT_Cu_y = np.matmul(np.matmul(yT, Cu), Y)\n",
    "        lI = np.dot(r_lambda, np.identity(nf))\n",
    "        yT_Cu_pu = np.matmul(np.matmul(yT, Cu), P[u])\n",
    "        X[u] = np.linalg.solve(yT_Cu_y + lI, yT_Cu_pu)\n",
    "\n",
    "def optimize_item(X, Y, C, P, ni, nf, r_lambda):\n",
    "    xT = np.transpose(X)\n",
    "    for i in range(ni):\n",
    "        Ci = np.diag(C[:, i])\n",
    "        xT_Ci_x = np.matmul(np.matmul(xT, Ci), X)\n",
    "        lI = np.dot(r_lambda, np.identity(nf))\n",
    "        xT_Ci_pi = np.matmul(np.matmul(xT, Ci), P[:, i])\n",
    "        Y[i] = np.linalg.solve(xT_Ci_x + lI, xT_Ci_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_errors = []\n",
    "confidence_errors = []\n",
    "regularization_list = []\n",
    "total_losses = []\n",
    "\n",
    "for i in range(15):\n",
    "    if i!=0:   \n",
    "        optimize_user(X, Y, C, P, nu, nf, r_lambda)\n",
    "        optimize_item(X, Y, C, P, ni, nf, r_lambda)\n",
    "    predict = np.matmul(X, np.transpose(Y))\n",
    "    predict_error, confidence_error, regularization, total_loss = loss_function(C, P, predict, X, Y, r_lambda)\n",
    "    \n",
    "    predict_errors.append(predict_error)\n",
    "    confidence_errors.append(confidence_error)\n",
    "    regularization_list.append(regularization)\n",
    "    total_losses.append(total_loss)\n",
    "    \n",
    "    print('----------------step %d----------------' % i)\n",
    "    print(\"predict error: %f\" % predict_error)\n",
    "    print(\"confidence error: %f\" % confidence_error)\n",
    "    print(\"regularization: %f\" % regularization)\n",
    "    print(\"total loss: %f\" % total_loss)\n",
    "    \n",
    "predict = np.matmul(X, np.transpose(Y))\n",
    "print('final predict')\n",
    "print([predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplots_adjust(wspace=100.0, hspace=20.0)\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "predict_error_line = fig.add_subplot(2, 2, 1)\n",
    "confidence_error_line = fig.add_subplot(2, 2, 2)\n",
    "regularization_error_line = fig.add_subplot(2, 2, 3)\n",
    "total_loss_line = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "predict_error_line.set_title(\"Predict Error\") \n",
    "predict_error_line.plot(predict_errors)\n",
    "\n",
    "confidence_error_line.set_title(\"Confidence Error\")\n",
    "confidence_error_line.plot(confidence_errors)\n",
    "\n",
    "regularization_error_line.set_title(\"Regularization\")\n",
    "regularization_error_line.plot(regularization_list)\n",
    "\n",
    "total_loss_line.set_title(\"Total Loss\")\n",
    "total_loss_line.plot(total_losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
