{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://sosul.network/series/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in range(1, 100):\n",
    "    params = {'order_by' : 'review', 'page' : f'{p}'}\n",
    "    res = requests.get(url, params = params)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "a_li = soup.find_all('div', class_='col-6 col-md-4 col-lg-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_review(name, url):\n",
    "    base_url = url\n",
    "    df = pd.DataFrame(columns = ['name', 'score', 'review'])\n",
    "    idx = 0\n",
    "    while True:\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        review_li = soup.find_all('div', class_ = 'comment widget p-cb')\n",
    "        for r in review_li:\n",
    "            comment = r.find('div', class_ = 'text')\n",
    "            score = comment.find('div', class_ = 'product-rate').find('star-rating')[':rating']\n",
    "            try:\n",
    "                r_text = comment.find('p', class_='content-txt').text\n",
    "            except:\n",
    "                r_text = comment.find('div', class_= 'ac-content').p.text\n",
    "        \n",
    "            df.loc[idx] = [name, score, r_text]\n",
    "            idx += 1\n",
    "\n",
    "        next_page = soup.find('ul', class_ = \"pagination justify-content-center\").find_all('li')\n",
    "        p_num = next_page[-1].a['href']\n",
    "        if p_num.split('=')[-1] == '#':\n",
    "            break\n",
    "        url = base_url + p_num\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "173\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['name', 'score', 'review'])\n",
    "idx = 0\n",
    "for i in a_li:\n",
    "    a = i.find('div', class_='product-title')\n",
    "    path = a.a['href']\n",
    "    url = 'https://sosul.network' + path\n",
    "    name = path.split('/')[-1]\n",
    "    a = make_review(name, url)\n",
    "    df = pd.concat([df, a])\n",
    "    idx += 1\n",
    "    print(len(a))\n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190</td>\n",
       "      <td>0.5</td>\n",
       "      <td>내가하면 오리지널 남이하면 파쿠리라는 갓 마인드를 가진작가님의 작품거기에 문피아에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>2.0</td>\n",
       "      <td>트위터 부녀자,페미코인을 제대로 탄 모범적인 소설그야말로 파쿠리의 집합체지만 다른소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>대충 200화전까지는 별 4개쯤 줘도 괜찮다고 여기는데 연재가 계속될수록 기승전구원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>0.5</td>\n",
       "      <td>장갤평) 환생좌 짜집기 그럼에도 불구하고 내로남불 가득한 '그' 소설작가의 전작에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>0.5</td>\n",
       "      <td>믿고 따라온 독자에게 똥물을 붓는 인성이 참 아름답다. 글이 어쩌고 하기 이전에 상...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>지겨움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3343</td>\n",
       "      <td>2.5</td>\n",
       "      <td>평범</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3343</td>\n",
       "      <td>4.0</td>\n",
       "      <td>입문용으로 ㅅㅌㅊ임</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>3343</td>\n",
       "      <td>3.0</td>\n",
       "      <td>소설볼꺼면 웹툰보셈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3343</td>\n",
       "      <td>2.5</td>\n",
       "      <td>먼치킨 헌터물의 교과서급. 그냥저냥 볼만하다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name score                                             review\n",
       "0     190   0.5  내가하면 오리지널 남이하면 파쿠리라는 갓 마인드를 가진작가님의 작품거기에 문피아에 ...\n",
       "1     190   2.0  트위터 부녀자,페미코인을 제대로 탄 모범적인 소설그야말로 파쿠리의 집합체지만 다른소...\n",
       "2     190   1.0  대충 200화전까지는 별 4개쯤 줘도 괜찮다고 여기는데 연재가 계속될수록 기승전구원...\n",
       "3     190   0.5  장갤평) 환생좌 짜집기 그럼에도 불구하고 내로남불 가득한 '그' 소설작가의 전작에서...\n",
       "4     190   0.5  믿고 따라온 독자에게 똥물을 붓는 인성이 참 아름답다. 글이 어쩌고 하기 이전에 상...\n",
       "..    ...   ...                                                ...\n",
       "168  3343   2.0                                                지겨움\n",
       "169  3343   2.5                                                 평범\n",
       "170  3343   4.0                                         입문용으로 ㅅㅌㅊ임\n",
       "171  3343   3.0                                         소설볼꺼면 웹툰보셈\n",
       "172  3343   2.5                          먼치킨 헌터물의 교과서급. 그냥저냥 볼만하다.\n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
